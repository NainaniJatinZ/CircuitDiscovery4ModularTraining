{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zephyr/anaconda3/envs/modmi/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is: mps\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from matplotlib.patches import Ellipse, Circle\n",
    "import time\n",
    "from itertools import islice\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from collections import defaultdict\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "import json \n",
    "\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "steps = 10000\n",
    "\n",
    "def cycle(iterable):\n",
    "    while True:\n",
    "        for x in iterable:\n",
    "            yield x\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(\"device is:\", device)\n",
    "\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "#torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "\n",
    "\n",
    "class BioLinear2D(nn.Module):\n",
    "\n",
    "    def __init__(self, in_dim, out_dim, in_fold=1, out_fold=1, out_ring=False):\n",
    "        super(BioLinear2D, self).__init__()\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.linear = nn.Linear(in_dim, out_dim)\n",
    "        self.in_fold = in_fold\n",
    "        self.out_fold = out_fold\n",
    "        assert in_dim % in_fold == 0\n",
    "        assert out_dim % out_fold == 0\n",
    "\n",
    "        #compute in_cor, shape: (in_dim_sqrt, in_dim_sqrt)\n",
    "        in_dim_fold = int(in_dim/in_fold)\n",
    "        out_dim_fold = int(out_dim/out_fold)\n",
    "        in_dim_sqrt = int(np.sqrt(in_dim_fold))\n",
    "        out_dim_sqrt = int(np.sqrt(out_dim_fold))\n",
    "        x = np.linspace(1/(2*in_dim_sqrt), 1-1/(2*in_dim_sqrt), num=in_dim_sqrt)\n",
    "        X, Y = np.meshgrid(x, x)\n",
    "        self.in_coordinates = torch.tensor(np.transpose(np.array([X.reshape(-1,), Y.reshape(-1,)])), dtype=torch.float)\n",
    "\n",
    "        # compute out_cor, shape: (out_dim_sqrt, out_dim_sqrt)\n",
    "        if out_ring:\n",
    "            thetas = np.linspace(1/(2*out_dim_fold)*2*np.pi, (1-1/(2*out_dim_fold))*2*np.pi, num=out_dim_fold)\n",
    "            self.out_coordinates = 0.5+torch.tensor(np.transpose(np.array([np.cos(thetas), np.sin(thetas)]))/4, dtype=torch.float)\n",
    "        else:\n",
    "            x = np.linspace(1/(2*out_dim_sqrt), 1-1/(2*out_dim_sqrt), num=out_dim_sqrt)\n",
    "            X, Y = np.meshgrid(x, x)\n",
    "            self.out_coordinates = torch.tensor(np.transpose(np.array([X.reshape(-1,), Y.reshape(-1,)])), dtype=torch.float)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "class BioMLP2D(nn.Module):\n",
    "    def __init__(self, in_dim=2, out_dim=2, w=2, depth=2, shp=None, token_embedding=False, embedding_size=None):\n",
    "        super(BioMLP2D, self).__init__()\n",
    "        if shp == None:\n",
    "            shp = [in_dim] + [w]*(depth-1) + [out_dim]\n",
    "            self.in_dim = in_dim\n",
    "            self.out_dim = out_dim\n",
    "            self.depth = depth\n",
    "\n",
    "        else:\n",
    "            self.in_dim = shp[0]\n",
    "            self.out_dim = shp[-1]\n",
    "            self.depth = len(shp) - 1\n",
    "        linear_list = []\n",
    "        for i in range(self.depth):\n",
    "            if i == 0:\n",
    "                # for modular addition\n",
    "                #linear_list.append(BioLinear(shp[i], shp[i+1], in_fold=2))\n",
    "                # for regression\n",
    "                linear_list.append(BioLinear2D(shp[i], shp[i+1], in_fold=1).to(device))\n",
    "            elif i == self.depth - 1:\n",
    "                linear_list.append(BioLinear2D(shp[i], shp[i+1], in_fold=1, out_ring=True).to(device))\n",
    "            else:\n",
    "                linear_list.append(BioLinear2D(shp[i], shp[i+1]).to(device))\n",
    "        self.linears = nn.ModuleList(linear_list)\n",
    "\n",
    "\n",
    "        if token_embedding == True:\n",
    "            # embedding size: number of tokens * embedding dimension\n",
    "            self.embedding = torch.nn.Parameter(torch.normal(0,1,size=embedding_size)).to(device)\n",
    "\n",
    "        self.shp = shp\n",
    "        # parameters for the bio-inspired trick\n",
    "        self.l0 = 0.5 # distance between two nearby layers\n",
    "        self.in_perm = nn.Parameter(torch.tensor(np.arange(int(self.in_dim/self.linears[0].in_fold)), dtype=torch.float))\n",
    "        self.out_perm = nn.Parameter(torch.tensor(np.arange(int(self.out_dim/self.linears[-1].out_fold)), dtype=torch.float))\n",
    "        self.top_k = 30\n",
    "        self.token_embedding = token_embedding\n",
    "\n",
    "    def forward(self, x):\n",
    "        shp = x.shape\n",
    "        x = x.reshape(shp[0],-1)\n",
    "        shp = x.shape\n",
    "        in_fold = self.linears[0].in_fold\n",
    "        x = x.reshape(shp[0], in_fold, int(shp[1]/in_fold))\n",
    "        x = x[:,:,self.in_perm.long()]\n",
    "        x = x.reshape(shp[0], shp[1])\n",
    "        f = torch.nn.SiLU()\n",
    "        for i in range(self.depth-1):\n",
    "            x = f(self.linears[i](x))\n",
    "        x = self.linears[-1](x)\n",
    "\n",
    "        out_perm_inv = torch.zeros(self.out_dim, dtype=torch.long)\n",
    "        out_perm_inv[self.out_perm.long()] = torch.arange(self.out_dim)\n",
    "        x = x[:,out_perm_inv]\n",
    "        #x = x[:,self.out_perm]\n",
    "\n",
    "        return x\n",
    "\n",
    "    def get_linear_layers(self):\n",
    "        return self.linears\n",
    "\n",
    "    def get_cc(self, weight_factor=2.0, bias_penalize=True, no_penalize_last=False):\n",
    "        # compute connection cost\n",
    "        cc = 0\n",
    "        num_linear = len(self.linears)\n",
    "        for i in range(num_linear):\n",
    "            if i == num_linear - 1 and no_penalize_last:\n",
    "                weight_factor = 0.\n",
    "            biolinear = self.linears[i].to(device)\n",
    "            dist = torch.sum(torch.abs(biolinear.out_coordinates.unsqueeze(dim=1) - biolinear.in_coordinates.unsqueeze(dim=0)),dim=2).to(device)\n",
    "            # print(\"yooo\")\n",
    "            # print(biolinear.linear.weight.device)\n",
    "            # print(dist.device)\n",
    "            # print(self.l0)\n",
    "            cc += torch.mean(torch.abs(biolinear.linear.weight)*(weight_factor*dist+self.l0))\n",
    "            if bias_penalize == True:\n",
    "                cc += torch.mean(torch.abs(biolinear.linear.bias)*(self.l0))\n",
    "        if self.token_embedding:\n",
    "            cc += torch.mean(torch.abs(self.embedding)*(self.l0))\n",
    "            #pass\n",
    "        return cc\n",
    "\n",
    "    def swap_weight(self, weights, j, k, swap_type=\"out\"):\n",
    "        with torch.no_grad():\n",
    "            if swap_type == \"in\":\n",
    "                temp = weights[:,j].clone()\n",
    "                weights[:,j] = weights[:,k].clone()\n",
    "                weights[:,k] = temp\n",
    "            elif swap_type == \"out\":\n",
    "                temp = weights[j].clone()\n",
    "                weights[j] = weights[k].clone()\n",
    "                weights[k] = temp\n",
    "            else:\n",
    "                raise Exception(\"Swap type {} is not recognized!\".format(swap_type))\n",
    "\n",
    "    def swap_bias(self, biases, j, k):\n",
    "        with torch.no_grad():\n",
    "            temp = biases[j].clone()\n",
    "            biases[j] = biases[k].clone()\n",
    "            biases[k] = temp\n",
    "\n",
    "    def swap(self, i, j, k):\n",
    "        # in the ith layer (of neurons), swap the jth and the kth neuron.\n",
    "        # Note: n layers of weights means n+1 layers of neurons.\n",
    "        # (incoming, outgoing) * weights + biases are swapped.\n",
    "        linears = self.get_linear_layers()\n",
    "        num_linear = len(linears)\n",
    "        if i == 0:\n",
    "            return\n",
    "            # for images, do not allow input_perm\n",
    "            # input layer, only has outgoing weights; update in_perm\n",
    "            weights = linears[i].linear.weight\n",
    "            infold = linears[i].in_fold\n",
    "            fold_dim = int(weights.shape[1]/infold)\n",
    "            for l in range(infold):\n",
    "                self.swap_weight(weights, j+fold_dim*l, k+fold_dim*l, swap_type=\"in\")\n",
    "            # change input_perm. do not allow input_perm for images\n",
    "            self.swap_bias(self.in_perm, j, k)\n",
    "        elif i == num_linear:\n",
    "            # output layer, only has incoming weights and biases; update out_perm\n",
    "            weights = linears[i-1].linear.weight\n",
    "            biases = linears[i-1].linear.bias\n",
    "            self.swap_weight(weights, j, k, swap_type=\"out\")\n",
    "            self.swap_bias(biases, j, k)\n",
    "            # change output_perm\n",
    "            self.swap_bias(self.out_perm, j, k)\n",
    "        else:\n",
    "            # middle layer : (incoming, outgoing) * weights, and biases\n",
    "            weights_in = linears[i-1].linear.weight\n",
    "            weights_out = linears[i].linear.weight\n",
    "            biases = linears[i-1].linear.bias\n",
    "            self.swap_weight(weights_in, j, k, swap_type=\"out\")\n",
    "            self.swap_weight(weights_out, j, k, swap_type=\"in\")\n",
    "            self.swap_bias(biases, j, k)\n",
    "\n",
    "    def get_top_id(self, i, top_k=20):\n",
    "        linears = self.get_linear_layers()\n",
    "        num_linear = len(linears)\n",
    "        if i == 0:\n",
    "            # input layer\n",
    "            weights = linears[i].linear.weight\n",
    "            score = torch.sum(torch.abs(weights), dim=0)\n",
    "            in_fold = linears[0].in_fold\n",
    "            #print(score.shape)\n",
    "            score = torch.sum(score.reshape(in_fold, int(score.shape[0]/in_fold)), dim=0)\n",
    "        elif i == num_linear:\n",
    "            # output layer\n",
    "            weights = linears[i-1].linear.weight\n",
    "            score = torch.sum(torch.abs(weights), dim=1)\n",
    "        else:\n",
    "            weights_in = linears[i-1].linear.weight\n",
    "            weights_out = linears[i].linear.weight\n",
    "            score = torch.sum(torch.abs(weights_out), dim=0) + torch.sum(torch.abs(weights_in), dim=1)\n",
    "        #print(score.shape)\n",
    "        top_index = torch.flip(torch.argsort(score),[0])[:top_k]\n",
    "        return top_index, score\n",
    "\n",
    "    def relocate_ij(self, i, j):\n",
    "        # In the ith layer (of neurons), relocate the jth neuron\n",
    "        linears = self.get_linear_layers()\n",
    "        num_linear = len(linears)\n",
    "        if i < num_linear:\n",
    "            num_neuron = int(linears[i].linear.weight.shape[1]/linears[i].in_fold)\n",
    "        else:\n",
    "            num_neuron = linears[i-1].linear.weight.shape[0]\n",
    "        ccs = []\n",
    "        for k in range(num_neuron):\n",
    "            self.swap(i,j,k)\n",
    "            ccs.append(self.get_cc())\n",
    "            self.swap(i,j,k)\n",
    "        k = torch.argmin(torch.stack(ccs))\n",
    "        self.swap(i,j,k)\n",
    "\n",
    "    def relocate_i(self, i):\n",
    "        # Relocate neurons in the ith layer\n",
    "        top_id = self.get_top_id(i, top_k=self.top_k)\n",
    "        for j in top_id[0]:\n",
    "            self.relocate_ij(i,j)\n",
    "\n",
    "    def relocate(self):\n",
    "        # Relocate neurons in the whole model\n",
    "        linears = self.get_linear_layers()\n",
    "        num_linear = len(linears)\n",
    "        for i in range(num_linear+1):\n",
    "            self.relocate_i(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 18342077.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/MNIST/raw/train-images-idx3-ubyte.gz to /tmp/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /tmp/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 2380951.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/MNIST/raw/train-labels-idx1-ubyte.gz to /tmp/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /tmp/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 5529744.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/MNIST/raw/t10k-images-idx3-ubyte.gz to /tmp/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /tmp/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 654477.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train = torchvision.datasets.MNIST(root=\"/tmp\", train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "test = torchvision.datasets.MNIST(root=\"/tmp\", train=False, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "data_size = 60000\n",
    "train = torch.utils.data.Subset(train, range(data_size))\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp = BioMLP2D(shp=(784,100,100,10)).to(\"cpu\")\n",
    "# mlp.load_state_dict(torch.load('fivemodels/bimt.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_activations(layer, input, output):\n",
    "    return output\n",
    "\n",
    "activations = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    activations.append(output)\n",
    "\n",
    "hooks = []\n",
    "\n",
    "def measure_improvement(patched_logits, original_logits):\n",
    "    # Compute L2 difference\n",
    "    difference_L2 = torch.norm(patched_logits - original_logits, p=2).item()\n",
    "    return difference_L2\n",
    "\n",
    "def patch_neuron(activation, neuron_idx, new_value):\n",
    "    patched_activation = activation.clone()\n",
    "    # print(\"To be patched: \", patched_activation[0, neuron_idx])\n",
    "    # print(\"patched to:\", new_value)\n",
    "    patched_activation[0, neuron_idx] = new_value\n",
    "    return patched_activation\n",
    "\n",
    "def sparsify2circuit_left(wt_tensor, indices_tensor):\n",
    "    zero_tensor = torch.zeros_like(wt_tensor)\n",
    "    zero_tensor[indices_tensor, :] = wt_tensor[indices_tensor, :]\n",
    "    return zero_tensor\n",
    "\n",
    "def sparsify2circuit_right(wt_tensor, indices_tensor):\n",
    "    zero_tensor = torch.zeros_like(wt_tensor)\n",
    "    zero_tensor[:, indices_tensor] = wt_tensor[:, indices_tensor]\n",
    "    return zero_tensor\n",
    "\n",
    "def get_top_n_from_each_layer(layer_dict, n):\n",
    "    # top_n = {}\n",
    "    top_try = {}\n",
    "    for layer in layer_dict:\n",
    "        # top_n[layer] = layer_dict[layer][:n]\n",
    "        top_try[layer] = [z[0][1] for z in layer_dict[layer][:n]]\n",
    "    return top_try\n",
    "\n",
    "def circuit_discovery(model, clean_tensor, corr_tensor):\n",
    "\n",
    "    # Attach hooks to all BioLinear2D layers\n",
    "    for layer in model.get_linear_layers():\n",
    "        hooks.append(layer.register_forward_hook(hook_fn))\n",
    "\n",
    "    model.eval() \n",
    "    original_output = model(clean_tensor)\n",
    "    clean_activations = activations.copy()  # Store activations after passing the clean tensor\n",
    "    activations.clear()\n",
    "    # print(clean_activations)\n",
    "    model(corr_tensor)\n",
    "    corrupted_activations = activations  # Store activations after passing the corrupted tensor\n",
    "    # print(corrupted_activations)\n",
    "\n",
    "    # Clear the hooks\n",
    "    for hook in hooks:\n",
    "        hook.remove()\n",
    "\n",
    "    improvements = []\n",
    "\n",
    "    # Iterate through layers\n",
    "    for layer_idx, (clean_act, corrupted_act) in enumerate(zip(clean_activations, corrupted_activations)):\n",
    "        num_neurons = clean_act.shape[1]\n",
    "        \n",
    "        for neuron_idx in range(num_neurons):\n",
    "            # Patch the neuron in the corrupted activations\n",
    "            patched_act = patch_neuron(corrupted_act, neuron_idx, clean_act[0, neuron_idx])\n",
    "\n",
    "            # Store the patched activations and keep others as-is\n",
    "            current_activations = [a.clone() for a in corrupted_activations]\n",
    "            current_activations[layer_idx] = patched_act\n",
    "            model.eval() \n",
    "\n",
    "            for inn_idx, sub_layer in enumerate(model.get_linear_layers()[layer_idx+1:]):\n",
    "                current_activations[layer_idx+inn_idx+1] = sub_layer(current_activations[layer_idx+inn_idx])\n",
    "\n",
    "            improvement = measure_improvement(current_activations[-1], original_output)  # Implement measure_improvement as required\n",
    "            improvements.append((layer_idx, neuron_idx, improvement))\n",
    "\n",
    "    sorted_neurons = sorted(improvements, key=lambda x: x[2], reverse=False)\n",
    "    return sorted_neurons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Load the MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root=\"/tmp\", train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "\n",
    "# Create datasets for each class\n",
    "class_3_dataset = [(image, label) for image, label in train_dataset if label == 3]\n",
    "class_5_dataset = [(image, label) for image, label in train_dataset if label == 5]\n",
    "class_6_dataset = [(image, label) for image, label in train_dataset if label == 6]\n",
    "class_8_dataset = [(image, label) for image, label in train_dataset if label == 8]\n",
    "\n",
    "class_1_dataset = [(image, label) for image, label in train_dataset if label == 1]\n",
    "class_4_dataset = [(image, label) for image, label in train_dataset if label == 4]\n",
    "class_7_dataset = [(image, label) for image, label in train_dataset if label == 7]\n",
    "class_9_dataset = [(image, label) for image, label in train_dataset if label == 9]\n",
    "\n",
    "# 1 3\n",
    "\n",
    "# 4 9\n",
    "\n",
    "# 7 9\n",
    "\n",
    "# 1 2 3 4 5 6 7 8 9 0\n",
    "# class_8_dataset = [(image, label) for image, label in train_dataset if label == 8]\n",
    "\n",
    "# Custom dataset for paired data\n",
    "class PairedDataset(Dataset):\n",
    "    def __init__(self, dataset1, dataset2):\n",
    "        self.dataset1 = dataset1\n",
    "        self.dataset2 = dataset2\n",
    "\n",
    "    def __len__(self):\n",
    "        # Ensure both datasets are of the same length\n",
    "        return min(len(self.dataset1), len(self.dataset2))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image1, _ = self.dataset1[idx % len(self.dataset1)]\n",
    "        image2, _ = self.dataset2[idx % len(self.dataset2)]\n",
    "        return image1, image2\n",
    "\n",
    "paired_dataset_1_3 = PairedDataset(class_3_dataset, class_1_dataset)\n",
    "paired_dataset_4_9 = PairedDataset(class_9_dataset, class_4_dataset)\n",
    "paired_dataset_7_9 = PairedDataset(class_9_dataset, class_7_dataset)\n",
    "# Create the paired datasets\n",
    "paired_dataset_3_8 = PairedDataset(class_3_dataset, class_8_dataset)\n",
    "paired_dataset_5_6 = PairedDataset(class_5_dataset, class_6_dataset)\n",
    "\n",
    "# Combine the paired datasets\n",
    "final_dataset = paired_dataset_3_8 + paired_dataset_5_6\n",
    "\n",
    "# Create a DataLoader for the final dataset\n",
    "final_loader = DataLoader(final_dataset, batch_size=1, shuffle=True)\n",
    "# loader_3_8 = DataLoader(paired_dataset_3_8, batch_size=1, shuffle=True)\n",
    "\n",
    "final_st = paired_dataset_1_3 + paired_dataset_4_9 + paired_dataset_7_9\n",
    "st_loader = DataLoader(final_st, batch_size=1, shuffle=True)\n",
    "\n",
    "\n",
    "# # Example: Iterate over the DataLoader\n",
    "# for i, (image1, image2) in enumerate(final_loader):\n",
    "#     print(f\"Batch {i}:\")\n",
    "#     print(\"Image from Class 3/5:\", image1.shape)\n",
    "#     print(\"Image from Class 6/8:\", image2.shape)\n",
    "#     if i == 5:  # Stop after 6 iterations for demonstration\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "import random\n",
    "import gc\n",
    "\n",
    "def subset_discovery(mlp, model_path, subset_size, dataset):\n",
    "    # subset_size = 500  # or any size you deem appropriate\n",
    "    subset_indices = random.sample(range(len(dataset)), subset_size)\n",
    "    subset = Subset(dataset, subset_indices)\n",
    "    # Create a DataLoader for the subset\n",
    "    subset_loader = DataLoader(subset, batch_size=1, shuffle=True)\n",
    "\n",
    "    value_dict = defaultdict(lambda: {'sum': 0, 'count': 0})\n",
    "    start = time.time()\n",
    "    for i, (image1, image2) in enumerate(subset_loader):\n",
    "        sorted_neurons =  circuit_discovery(mlp, image2, image1)\n",
    "        for layer, neuron, value in sorted_neurons:\n",
    "            value_dict[(layer, neuron)]['sum'] += value\n",
    "            value_dict[(layer, neuron)]['count'] += 1\n",
    "\n",
    "    average_values = {}\n",
    "    for key, data in value_dict.items():\n",
    "        average = data['sum'] / data['count']\n",
    "        average_values[key] = average\n",
    "\n",
    "    data = average_values\n",
    "    # Separate the dictionary for each layer and sort according to the logit value\n",
    "    layer_dict = {}\n",
    "    for (layer, neuron), logit in data.items():\n",
    "        if layer not in layer_dict:\n",
    "            layer_dict[layer] = []\n",
    "        layer_dict[layer].append(((layer, neuron), logit))\n",
    "\n",
    "        # Sort each layer's list by logit value in descending order\n",
    "    for layer in layer_dict:\n",
    "        layer_dict[layer].sort(key=lambda x: x[1], reverse=False)\n",
    "\n",
    "        # stop = \n",
    "    top_15 = get_top_n_from_each_layer(layer_dict, 25)\n",
    "    # model_result[val] = top_15\n",
    "    stop_time = time.time()-start\n",
    "    print(\"Model: \", model_path)\n",
    "    print(\"Time to discover circuit: \", time.time()-start)\n",
    "\n",
    "    avg_logit_diff = 0\n",
    "    for i, (image1, image2) in enumerate(subset_loader):\n",
    "        clean_tensor = image2\n",
    "        mlp.eval()\n",
    "        with torch.no_grad():\n",
    "            og_op = mlp(clean_tensor)\n",
    "            clean_activations = activations.copy()\n",
    "\n",
    "        sub_graph_act = [a.clone() for a in clean_activations]\n",
    "\n",
    "        for inn_idx, sub_layer in enumerate(mlp.get_linear_layers()[1:]):\n",
    "            # print(inn_idx+layer_idx)\n",
    "            zero_tensor = torch.zeros_like(sub_graph_act[inn_idx])\n",
    "            zero_tensor[0, torch.tensor(top_15[inn_idx])] = sub_graph_act[inn_idx][0, torch.tensor(top_15[inn_idx])]\n",
    "            sub_graph_act[inn_idx] = zero_tensor\n",
    "            # print(sub_graph_act[inn_idx].shape)\n",
    "            sub_graph_act[inn_idx+1] = sub_layer(sub_graph_act[inn_idx])\n",
    "\n",
    "        avg_logit_diff += measure_improvement(sub_graph_act[-1], og_op)\n",
    "        # break\n",
    "    avg_logit_diff = avg_logit_diff/len(subset_loader)\n",
    "    print(\"Average Logit Diff: \", avg_logit_diff)\n",
    "\n",
    "    avg_spar = 0\n",
    "    for ii in range(3):\n",
    "        biolinear = mlp.linears[ii]\n",
    "        p = biolinear.linear.weight.clone()\n",
    "        if ii == 0:\n",
    "            p = sparsify2circuit_left(p, torch.tensor(top_15[ii]))\n",
    "        else:\n",
    "            p = sparsify2circuit_right(p, torch.tensor(top_15[ii]))\n",
    "            p = sparsify2circuit_left(p, torch.tensor(top_15[ii]))\n",
    "\n",
    "        W = p.T.detach().numpy()\n",
    "        n_sparsity = (np.abs(W)<0.0009).sum()\n",
    "        avg_spar+=n_sparsity/(W.shape[0]*W.shape[1])\n",
    "        # print(\"Percentage Sparsity:\", n_sparsity/(W.shape[0]*W.shape[1]))\n",
    "    avg_spar = avg_spar/3\n",
    "    print(\"Average Sparsity: \", avg_spar)\n",
    "    \n",
    "    return [top_15, avg_logit_diff, stop_time, avg_spar]\n",
    "            \n",
    "        # Run circuit discovery on the bootstrap sample\n",
    "        # top_15_neurons, avg_logit_diff, stop_time, sparsity = circuit_discovery(mlp, subset_loader)\n",
    "\n",
    "        # Store the results\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"fivemodels/bimt.pt\", \"fivemodels/l1local.pt\", \"fivemodels/l1only.pt\", \"fivemodels/l1swap.pt\", \"fivemodels/fully_dense.pt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x2ae7e4810>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  fivemodels/bimt.pt\n",
      "Time to discover circuit:  8.460631132125854\n",
      "Average Logit Diff:  1.5535548198223115\n",
      "Average Sparsity:  0.9835238095238096\n",
      "--------------------\n",
      "Model:  fivemodels/bimt.pt\n",
      "Time to discover circuit:  8.432724952697754\n",
      "Average Logit Diff:  1.1567475670576095\n",
      "Average Sparsity:  0.9875960884353742\n",
      "--------------------\n",
      "Model:  fivemodels/bimt.pt\n",
      "Time to discover circuit:  8.433588981628418\n",
      "Average Logit Diff:  0.931290403008461\n",
      "Average Sparsity:  0.9839163265306122\n",
      "--------------------\n",
      "Model:  fivemodels/bimt.pt\n",
      "Time to discover circuit:  8.439559936523438\n",
      "Average Logit Diff:  0.9008853617310524\n",
      "Average Sparsity:  0.9857227891156463\n",
      "--------------------\n",
      "Model:  fivemodels/bimt.pt\n",
      "Time to discover circuit:  8.456236124038696\n",
      "Average Logit Diff:  1.1365771555900575\n",
      "Average Sparsity:  0.9856134353741496\n",
      "--------------------\n",
      "Model:  fivemodels/bimt.pt\n",
      "Time to discover circuit:  8.431932210922241\n",
      "Average Logit Diff:  0.9797960150241852\n",
      "Average Sparsity:  0.9858933673469389\n",
      "--------------------\n",
      "Model:  fivemodels/bimt.pt\n",
      "Time to discover circuit:  8.430607795715332\n",
      "Average Logit Diff:  1.0108322423696519\n",
      "Average Sparsity:  0.984590306122449\n",
      "--------------------\n",
      "Model:  fivemodels/bimt.pt\n",
      "Time to discover circuit:  8.437210321426392\n",
      "Average Logit Diff:  0.8563299605250358\n",
      "Average Sparsity:  0.976595068027211\n",
      "--------------------\n",
      "Model:  fivemodels/bimt.pt\n",
      "Time to discover circuit:  8.437252759933472\n",
      "Average Logit Diff:  0.980874879360199\n",
      "Average Sparsity:  0.9879651360544218\n",
      "--------------------\n",
      "Model:  fivemodels/bimt.pt\n",
      "Time to discover circuit:  8.458576917648315\n",
      "Average Logit Diff:  1.819153107404709\n",
      "Average Sparsity:  0.9872474489795918\n",
      "--------------------\n",
      "Model:  fivemodels/bimt.pt\n",
      "Time to discover circuit:  8.444602727890015\n",
      "Average Logit Diff:  1.5000819265842438\n",
      "Average Sparsity:  0.9850498299319727\n",
      "--------------------\n",
      "Model:  fivemodels/bimt.pt\n",
      "Time to discover circuit:  8.456135272979736\n",
      "Average Logit Diff:  1.3849057722091676\n",
      "Average Sparsity:  0.9802088435374149\n",
      "--------------------\n",
      "Model:  fivemodels/bimt.pt\n",
      "Time to discover circuit:  8.455196857452393\n",
      "Average Logit Diff:  2.0933210027217863\n",
      "Average Sparsity:  0.9786627551020408\n",
      "--------------------\n",
      "Model:  fivemodels/bimt.pt\n",
      "Time to discover circuit:  8.455372095108032\n",
      "Average Logit Diff:  0.9129228213429451\n",
      "Average Sparsity:  0.9852933673469387\n",
      "--------------------\n",
      "Model:  fivemodels/bimt.pt\n",
      "Time to discover circuit:  8.478769063949585\n",
      "Average Logit Diff:  0.9751287257671356\n",
      "Average Sparsity:  0.9828569727891155\n",
      "--------------------\n",
      "Model:  fivemodels/bimt.pt\n",
      "Time to discover circuit:  8.46214509010315\n",
      "Average Logit Diff:  1.0764299470186234\n",
      "Average Sparsity:  0.9821207482993198\n",
      "--------------------\n",
      "Model:  fivemodels/bimt.pt\n",
      "Time to discover circuit:  8.484696865081787\n",
      "Average Logit Diff:  0.8946991401910782\n",
      "Average Sparsity:  0.9836719387755103\n",
      "--------------------\n",
      "Model:  fivemodels/bimt.pt\n",
      "Time to discover circuit:  8.470113039016724\n",
      "Average Logit Diff:  3.5129995131492615\n",
      "Average Sparsity:  0.9838974489795919\n",
      "--------------------\n",
      "Model:  fivemodels/bimt.pt\n",
      "Time to discover circuit:  8.476680040359497\n",
      "Average Logit Diff:  1.996212522983551\n",
      "Average Sparsity:  0.9868697278911563\n",
      "--------------------\n",
      "Model:  fivemodels/bimt.pt\n",
      "Time to discover circuit:  8.46844220161438\n",
      "Average Logit Diff:  0.8905001351237297\n",
      "Average Sparsity:  0.9817602040816326\n",
      "--------------------\n",
      "Done with  fivemodels/bimt.pt\n",
      "Model:  fivemodels/l1local.pt\n",
      "Time to discover circuit:  8.47469687461853\n",
      "Average Logit Diff:  0.8893840858340263\n",
      "Average Sparsity:  0.9805277210884354\n",
      "--------------------\n",
      "Model:  fivemodels/l1local.pt\n",
      "Time to discover circuit:  8.4653799533844\n",
      "Average Logit Diff:  3.0694597220420836\n",
      "Average Sparsity:  0.9818557823129251\n",
      "--------------------\n",
      "Model:  fivemodels/l1local.pt\n",
      "Time to discover circuit:  8.467355251312256\n",
      "Average Logit Diff:  1.017412866950035\n",
      "Average Sparsity:  0.9842586734693878\n",
      "--------------------\n",
      "Model:  fivemodels/l1local.pt\n",
      "Time to discover circuit:  8.487090110778809\n",
      "Average Logit Diff:  0.9237616947293281\n",
      "Average Sparsity:  0.9804039115646258\n",
      "--------------------\n",
      "Model:  fivemodels/l1local.pt\n",
      "Time to discover circuit:  8.465073823928833\n",
      "Average Logit Diff:  0.8893760785460472\n",
      "Average Sparsity:  0.979017857142857\n",
      "--------------------\n",
      "Model:  fivemodels/l1local.pt\n",
      "Time to discover circuit:  8.482328176498413\n",
      "Average Logit Diff:  0.911340688765049\n",
      "Average Sparsity:  0.9807610544217686\n",
      "--------------------\n",
      "Model:  fivemodels/l1local.pt\n",
      "Time to discover circuit:  8.499391794204712\n",
      "Average Logit Diff:  1.3719220024347305\n",
      "Average Sparsity:  0.9823217687074829\n",
      "--------------------\n",
      "Model:  fivemodels/l1local.pt\n",
      "Time to discover circuit:  8.733206987380981\n",
      "Average Logit Diff:  1.0181226170063018\n",
      "Average Sparsity:  0.9800593537414967\n",
      "--------------------\n",
      "Model:  fivemodels/l1local.pt\n",
      "Time to discover circuit:  8.763726949691772\n",
      "Average Logit Diff:  1.9062383711338042\n",
      "Average Sparsity:  0.9791367346938774\n",
      "--------------------\n",
      "Model:  fivemodels/l1local.pt\n",
      "Time to discover circuit:  9.374139070510864\n",
      "Average Logit Diff:  1.523095588684082\n",
      "Average Sparsity:  0.9782340136054422\n",
      "--------------------\n",
      "Model:  fivemodels/l1local.pt\n",
      "Time to discover circuit:  8.770164966583252\n",
      "Average Logit Diff:  2.6817772674560545\n",
      "Average Sparsity:  0.9809882653061225\n",
      "--------------------\n",
      "Model:  fivemodels/l1local.pt\n",
      "Time to discover circuit:  8.906233072280884\n",
      "Average Logit Diff:  1.4795824456214905\n",
      "Average Sparsity:  0.9811202380952381\n",
      "--------------------\n",
      "Model:  fivemodels/l1local.pt\n",
      "Time to discover circuit:  8.626734018325806\n",
      "Average Logit Diff:  0.9222710618376732\n",
      "Average Sparsity:  0.9852408163265306\n",
      "--------------------\n",
      "Model:  fivemodels/l1local.pt\n",
      "Time to discover circuit:  8.709211826324463\n",
      "Average Logit Diff:  1.5417990970611573\n",
      "Average Sparsity:  0.9813482993197279\n",
      "--------------------\n",
      "Model:  fivemodels/l1local.pt\n",
      "Time to discover circuit:  8.591546058654785\n",
      "Average Logit Diff:  0.9103638124465943\n",
      "Average Sparsity:  0.9829294217687075\n",
      "--------------------\n",
      "Model:  fivemodels/l1local.pt\n",
      "Time to discover circuit:  8.537086963653564\n",
      "Average Logit Diff:  1.0969799065589905\n",
      "Average Sparsity:  0.9825232993197278\n",
      "--------------------\n",
      "Model:  fivemodels/l1local.pt\n",
      "Time to discover circuit:  8.53276801109314\n",
      "Average Logit Diff:  1.6015162038803101\n",
      "Average Sparsity:  0.9825926870748299\n",
      "--------------------\n",
      "Model:  fivemodels/l1local.pt\n",
      "Time to discover circuit:  8.627899885177612\n",
      "Average Logit Diff:  1.9639249634742737\n",
      "Average Sparsity:  0.9794074829931972\n",
      "--------------------\n",
      "Model:  fivemodels/l1local.pt\n",
      "Time to discover circuit:  8.663865089416504\n",
      "Average Logit Diff:  2.6664504480361937\n",
      "Average Sparsity:  0.9828363945578231\n",
      "--------------------\n",
      "Model:  fivemodels/l1local.pt\n",
      "Time to discover circuit:  8.773804903030396\n",
      "Average Logit Diff:  0.9413336330652237\n",
      "Average Sparsity:  0.9839212585034014\n",
      "--------------------\n",
      "Done with  fivemodels/l1local.pt\n",
      "Model:  fivemodels/l1only.pt\n",
      "Time to discover circuit:  8.636721849441528\n",
      "Average Logit Diff:  1.0366199213266372\n",
      "Average Sparsity:  0.9564974489795919\n",
      "--------------------\n",
      "Model:  fivemodels/l1only.pt\n",
      "Time to discover circuit:  8.611220359802246\n",
      "Average Logit Diff:  1.4264559721946717\n",
      "Average Sparsity:  0.9544523809523809\n",
      "--------------------\n",
      "Model:  fivemodels/l1only.pt\n",
      "Time to discover circuit:  8.547019958496094\n",
      "Average Logit Diff:  1.2204258692264558\n",
      "Average Sparsity:  0.9569773809523809\n",
      "--------------------\n",
      "Model:  fivemodels/l1only.pt\n",
      "Time to discover circuit:  8.551016330718994\n",
      "Average Logit Diff:  1.0680758273601532\n",
      "Average Sparsity:  0.9572962585034014\n",
      "--------------------\n",
      "Model:  fivemodels/l1only.pt\n",
      "Time to discover circuit:  8.54444432258606\n",
      "Average Logit Diff:  1.117320065498352\n",
      "Average Sparsity:  0.9560894557823129\n",
      "--------------------\n",
      "Model:  fivemodels/l1only.pt\n",
      "Time to discover circuit:  8.543462038040161\n",
      "Average Logit Diff:  0.925649857223034\n",
      "Average Sparsity:  0.9568784013605441\n",
      "--------------------\n",
      "Model:  fivemodels/l1only.pt\n",
      "Time to discover circuit:  8.670390844345093\n",
      "Average Logit Diff:  0.9504790887236595\n",
      "Average Sparsity:  0.9558579931972789\n",
      "--------------------\n",
      "Model:  fivemodels/l1only.pt\n",
      "Time to discover circuit:  8.636873006820679\n",
      "Average Logit Diff:  0.9796970519423485\n",
      "Average Sparsity:  0.955059693877551\n",
      "--------------------\n",
      "Model:  fivemodels/l1only.pt\n",
      "Time to discover circuit:  8.574491262435913\n",
      "Average Logit Diff:  1.6933231675624847\n",
      "Average Sparsity:  0.956000850340136\n",
      "--------------------\n",
      "Model:  fivemodels/l1only.pt\n",
      "Time to discover circuit:  8.638538122177124\n",
      "Average Logit Diff:  2.817068266868591\n",
      "Average Sparsity:  0.9551544217687075\n",
      "--------------------\n",
      "Model:  fivemodels/l1only.pt\n",
      "Time to discover circuit:  8.601860046386719\n",
      "Average Logit Diff:  1.3853357285261154\n",
      "Average Sparsity:  0.9559039115646258\n",
      "--------------------\n",
      "Model:  fivemodels/l1only.pt\n",
      "Time to discover circuit:  8.612591028213501\n",
      "Average Logit Diff:  1.0595118278264999\n",
      "Average Sparsity:  0.9548107142857143\n",
      "--------------------\n",
      "Model:  fivemodels/l1only.pt\n",
      "Time to discover circuit:  8.611711978912354\n",
      "Average Logit Diff:  1.1763228124380112\n",
      "Average Sparsity:  0.9544693877551021\n",
      "--------------------\n",
      "Model:  fivemodels/l1only.pt\n",
      "Time to discover circuit:  8.604225158691406\n",
      "Average Logit Diff:  0.9340414041280747\n",
      "Average Sparsity:  0.9566275510204082\n",
      "--------------------\n",
      "Model:  fivemodels/l1only.pt\n",
      "Time to discover circuit:  8.577924013137817\n",
      "Average Logit Diff:  1.9159430396556854\n",
      "Average Sparsity:  0.9560037414965986\n",
      "--------------------\n",
      "Model:  fivemodels/l1only.pt\n",
      "Time to discover circuit:  8.583361625671387\n",
      "Average Logit Diff:  0.9531938573718071\n",
      "Average Sparsity:  0.9561386054421769\n",
      "--------------------\n",
      "Model:  fivemodels/l1only.pt\n",
      "Time to discover circuit:  8.707183837890625\n",
      "Average Logit Diff:  0.9511845874786377\n",
      "Average Sparsity:  0.9561045918367347\n",
      "--------------------\n",
      "Model:  fivemodels/l1only.pt\n",
      "Time to discover circuit:  8.610083103179932\n",
      "Average Logit Diff:  1.2168172973394393\n",
      "Average Sparsity:  0.954651530612245\n",
      "--------------------\n",
      "Model:  fivemodels/l1only.pt\n",
      "Time to discover circuit:  8.623684167861938\n",
      "Average Logit Diff:  2.1520807433128355\n",
      "Average Sparsity:  0.9559678571428573\n",
      "--------------------\n",
      "Model:  fivemodels/l1only.pt\n",
      "Time to discover circuit:  8.660642147064209\n",
      "Average Logit Diff:  2.678389210700989\n",
      "Average Sparsity:  0.956387074829932\n",
      "--------------------\n",
      "Done with  fivemodels/l1only.pt\n",
      "Model:  fivemodels/l1swap.pt\n",
      "Time to discover circuit:  8.711720943450928\n",
      "Average Logit Diff:  1.6473699557781218\n",
      "Average Sparsity:  0.9580758503401361\n",
      "--------------------\n",
      "Model:  fivemodels/l1swap.pt\n",
      "Time to discover circuit:  8.596059799194336\n",
      "Average Logit Diff:  1.947971098423004\n",
      "Average Sparsity:  0.9587085034013606\n",
      "--------------------\n",
      "Model:  fivemodels/l1swap.pt\n",
      "Time to discover circuit:  8.660693883895874\n",
      "Average Logit Diff:  1.5973270630836487\n",
      "Average Sparsity:  0.9579246598639456\n",
      "--------------------\n",
      "Model:  fivemodels/l1swap.pt\n",
      "Time to discover circuit:  8.850825071334839\n",
      "Average Logit Diff:  1.278243677020073\n",
      "Average Sparsity:  0.9579377551020408\n",
      "--------------------\n",
      "Model:  fivemodels/l1swap.pt\n",
      "Time to discover circuit:  8.819432020187378\n",
      "Average Logit Diff:  1.5673993813991547\n",
      "Average Sparsity:  0.9579527210884353\n",
      "--------------------\n",
      "Model:  fivemodels/l1swap.pt\n",
      "Time to discover circuit:  8.773491144180298\n",
      "Average Logit Diff:  1.2214885407686233\n",
      "Average Sparsity:  0.9579357142857142\n",
      "--------------------\n",
      "Model:  fivemodels/l1swap.pt\n",
      "Time to discover circuit:  8.715284824371338\n",
      "Average Logit Diff:  2.050569006204605\n",
      "Average Sparsity:  0.957872619047619\n",
      "--------------------\n",
      "Model:  fivemodels/l1swap.pt\n",
      "Time to discover circuit:  8.660660028457642\n",
      "Average Logit Diff:  0.9221210664510727\n",
      "Average Sparsity:  0.9597964285714286\n",
      "--------------------\n",
      "Model:  fivemodels/l1swap.pt\n",
      "Time to discover circuit:  8.695621967315674\n",
      "Average Logit Diff:  0.8945733812451363\n",
      "Average Sparsity:  0.9577875850340135\n",
      "--------------------\n",
      "Model:  fivemodels/l1swap.pt\n",
      "Time to discover circuit:  8.742079973220825\n",
      "Average Logit Diff:  3.0345587611198424\n",
      "Average Sparsity:  0.9577639455782313\n",
      "--------------------\n",
      "Model:  fivemodels/l1swap.pt\n",
      "Time to discover circuit:  8.701833963394165\n",
      "Average Logit Diff:  2.058978555202484\n",
      "Average Sparsity:  0.9584926870748299\n",
      "--------------------\n",
      "Model:  fivemodels/l1swap.pt\n",
      "Time to discover circuit:  8.584760904312134\n",
      "Average Logit Diff:  1.6091042399406432\n",
      "Average Sparsity:  0.9589780612244899\n",
      "--------------------\n",
      "Model:  fivemodels/l1swap.pt\n",
      "Time to discover circuit:  8.605845928192139\n",
      "Average Logit Diff:  2.3923365473747253\n",
      "Average Sparsity:  0.959104081632653\n",
      "--------------------\n",
      "Model:  fivemodels/l1swap.pt\n",
      "Time to discover circuit:  8.6374831199646\n",
      "Average Logit Diff:  1.3573404729366303\n",
      "Average Sparsity:  0.9582732993197279\n",
      "--------------------\n",
      "Model:  fivemodels/l1swap.pt\n",
      "Time to discover circuit:  8.690865993499756\n",
      "Average Logit Diff:  0.9138756623864174\n",
      "Average Sparsity:  0.9583455782312925\n",
      "--------------------\n",
      "Model:  fivemodels/l1swap.pt\n",
      "Time to discover circuit:  8.635173320770264\n",
      "Average Logit Diff:  0.8433702157437801\n",
      "Average Sparsity:  0.9579093537414965\n",
      "--------------------\n",
      "Model:  fivemodels/l1swap.pt\n",
      "Time to discover circuit:  8.695991039276123\n",
      "Average Logit Diff:  1.1368486701697111\n",
      "Average Sparsity:  0.9597365646258503\n",
      "--------------------\n",
      "Model:  fivemodels/l1swap.pt\n",
      "Time to discover circuit:  8.683163166046143\n",
      "Average Logit Diff:  1.1323078328371048\n",
      "Average Sparsity:  0.9595869047619048\n",
      "--------------------\n",
      "Model:  fivemodels/l1swap.pt\n",
      "Time to discover circuit:  8.681505918502808\n",
      "Average Logit Diff:  2.05873916387558\n",
      "Average Sparsity:  0.9585806122448979\n",
      "--------------------\n",
      "Model:  fivemodels/l1swap.pt\n",
      "Time to discover circuit:  8.647340774536133\n",
      "Average Logit Diff:  4.163251781463623\n",
      "Average Sparsity:  0.9577221088435374\n",
      "--------------------\n",
      "Done with  fivemodels/l1swap.pt\n",
      "Model:  fivemodels/fully_dense.pt\n",
      "Time to discover circuit:  8.688976049423218\n",
      "Average Logit Diff:  14.986369409561156\n",
      "Average Sparsity:  0.8635619047619048\n",
      "--------------------\n",
      "Model:  fivemodels/fully_dense.pt\n",
      "Time to discover circuit:  8.608391761779785\n",
      "Average Logit Diff:  4.13684965133667\n",
      "Average Sparsity:  0.8635824829931972\n",
      "--------------------\n",
      "Model:  fivemodels/fully_dense.pt\n",
      "Time to discover circuit:  8.627761125564575\n",
      "Average Logit Diff:  6.000760011672973\n",
      "Average Sparsity:  0.8635278911564624\n",
      "--------------------\n",
      "Model:  fivemodels/fully_dense.pt\n",
      "Time to discover circuit:  8.624558210372925\n",
      "Average Logit Diff:  4.940297541618347\n",
      "Average Sparsity:  0.8635484693877551\n",
      "--------------------\n",
      "Model:  fivemodels/fully_dense.pt\n",
      "Time to discover circuit:  8.6580069065094\n",
      "Average Logit Diff:  13.137570981979371\n",
      "Average Sparsity:  0.8635824829931972\n",
      "--------------------\n",
      "Model:  fivemodels/fully_dense.pt\n",
      "Time to discover circuit:  8.63805079460144\n",
      "Average Logit Diff:  9.087825775146484\n",
      "Average Sparsity:  0.8635824829931972\n",
      "--------------------\n",
      "Model:  fivemodels/fully_dense.pt\n",
      "Time to discover circuit:  8.629097938537598\n",
      "Average Logit Diff:  11.217043781280518\n",
      "Average Sparsity:  0.8635654761904762\n",
      "--------------------\n",
      "Model:  fivemodels/fully_dense.pt\n",
      "Time to discover circuit:  8.644166946411133\n",
      "Average Logit Diff:  2.2191719579696656\n",
      "Average Sparsity:  0.8635988095238095\n",
      "--------------------\n",
      "Model:  fivemodels/fully_dense.pt\n",
      "Time to discover circuit:  8.632943153381348\n",
      "Average Logit Diff:  6.314568786621094\n",
      "Average Sparsity:  0.8635697278911566\n",
      "--------------------\n",
      "Model:  fivemodels/fully_dense.pt\n",
      "Time to discover circuit:  8.650168180465698\n",
      "Average Logit Diff:  5.107019515037536\n",
      "Average Sparsity:  0.8636413265306123\n",
      "--------------------\n",
      "Model:  fivemodels/fully_dense.pt\n",
      "Time to discover circuit:  8.659231185913086\n",
      "Average Logit Diff:  8.979970626831054\n",
      "Average Sparsity:  0.8636420068027211\n",
      "--------------------\n",
      "Model:  fivemodels/fully_dense.pt\n",
      "Time to discover circuit:  8.65843391418457\n",
      "Average Logit Diff:  6.686047987937927\n",
      "Average Sparsity:  0.8635704081632652\n",
      "--------------------\n",
      "Model:  fivemodels/fully_dense.pt\n",
      "Time to discover circuit:  8.64476490020752\n",
      "Average Logit Diff:  4.352315554618835\n",
      "Average Sparsity:  0.8636278911564625\n",
      "--------------------\n",
      "Model:  fivemodels/fully_dense.pt\n",
      "Time to discover circuit:  8.650579929351807\n",
      "Average Logit Diff:  8.122683959007263\n",
      "Average Sparsity:  0.8636420068027211\n",
      "--------------------\n",
      "Model:  fivemodels/fully_dense.pt\n",
      "Time to discover circuit:  8.672306060791016\n",
      "Average Logit Diff:  8.521220493316651\n",
      "Average Sparsity:  0.8635824829931972\n",
      "--------------------\n",
      "Model:  fivemodels/fully_dense.pt\n",
      "Time to discover circuit:  8.669589042663574\n",
      "Average Logit Diff:  3.898974983692169\n",
      "Average Sparsity:  0.8635527210884354\n",
      "--------------------\n",
      "Model:  fivemodels/fully_dense.pt\n",
      "Time to discover circuit:  8.667364835739136\n",
      "Average Logit Diff:  7.7466286945343015\n",
      "Average Sparsity:  0.863566156462585\n",
      "--------------------\n",
      "Model:  fivemodels/fully_dense.pt\n",
      "Time to discover circuit:  8.67004108428955\n",
      "Average Logit Diff:  6.452333159446717\n",
      "Average Sparsity:  0.8635896258503402\n",
      "--------------------\n",
      "Model:  fivemodels/fully_dense.pt\n",
      "Time to discover circuit:  8.680108785629272\n",
      "Average Logit Diff:  8.68707983970642\n",
      "Average Sparsity:  0.863678231292517\n",
      "--------------------\n",
      "Model:  fivemodels/fully_dense.pt\n",
      "Time to discover circuit:  8.686429023742676\n",
      "Average Logit Diff:  1.8318277156352998\n",
      "Average Sparsity:  0.8635903061224489\n",
      "--------------------\n",
      "Done with  fivemodels/fully_dense.pt\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "import random\n",
    "import gc\n",
    "\n",
    "# Assuming you have a function `circuit_discovery` that returns top_15_neurons, avg_logit_diff, stop_time, sparsity\n",
    "# def circuit_discovery(model, data_loader): ...\n",
    "\n",
    "# Your DataLoader and models setup remains the same\n",
    "final_loader = DataLoader(final_dataset, batch_size=1, shuffle=True)\n",
    "# models = [\"fivemodels/bimt.pt\", \"fivemodels/l1local.pt\", \"fivemodels/l1only.pt\", \"fivemodels/l1swap.pt\", \"fivemodels/fully_dense.pt\"]\n",
    "models = [\"fivemodels/bimt.pt\", \"fivemodels/l1local.pt\", \"fivemodels/l1only.pt\", \"fivemodels/l1swap.pt\", \"fivemodels/fully_dense.pt\"]\n",
    "\n",
    "# Number of bootstrap samples\n",
    "n_bootstrap_samples = 20  # or any other number you deem sufficient\n",
    "\n",
    "model_result = {}\n",
    "for val, model_path in enumerate(models):\n",
    "    mlp = BioMLP2D(shp=(784,100,100,10)).to(\"cpu\")\n",
    "    mlp.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    # Prepare to collect bootstrap results\n",
    "    bootstrap_results = {'top_15': [], 'avg_logit_diff': [], 'stop_time': [], 'sparsity': []}\n",
    "    subset_size = 100\n",
    "    for _ in range(n_bootstrap_samples):\n",
    "        # subset_indices = random.sample(range(len(final_dataset)), 1000)\n",
    "        # subset = Subset(final_dataset, subset_indices)\n",
    "        # # Create a DataLoader for the subset\n",
    "        # subset_loader = DataLoader(subset, batch_size=1, shuffle=True)\n",
    "        \n",
    "        subset_results = subset_discovery(mlp, model_path, subset_size, final_st)    \n",
    "        # Run circuit discovery on the bootstrap sample\n",
    "        # top_15_neurons, avg_logit_diff, stop_time, sparsity = circuit_discovery(mlp, subset_loader)\n",
    "\n",
    "        # Store the results\n",
    "        bootstrap_results['top_15'].append(subset_results[0])\n",
    "        bootstrap_results['avg_logit_diff'].append(subset_results[1])\n",
    "        bootstrap_results['stop_time'].append(subset_results[2])\n",
    "        bootstrap_results['sparsity'].append(subset_results[3])\n",
    "        gc.collect()\n",
    "        print(\"-\"*20)\n",
    "\n",
    "    # Store results for this model\n",
    "    print(\"Done with \", model_path)\n",
    "    model_result[val] = bootstrap_results\n",
    "    with open('model_results_st.json', 'w') as json_file:\n",
    "        json.dump(model_result, json_file)\n",
    "\n",
    "# After this, model_result will have the bootstrap distributions for each metric for each model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fivemodels/bimt.pt': {'avg_logit_diff': [1.3281621509492398, 0.30065939075883985], 'stop_time': [8.453461146354675, 0.007918620268235272], 'sparsity': [0.9839527806122449, 0.0013898862397499897]}, 'fivemodels/l1local.pt': {'avg_logit_diff': [1.4663056277781723, 0.3158338925922389], 'stop_time': [8.647523629665375, 0.1009415653694821], 'sparsity': [0.98147425170068, 0.0008743501029641102]}, 'fivemodels/l1only.pt': {'avg_logit_diff': [1.382896779835224, 0.27016060535554876], 'stop_time': [8.607308506965637, 0.02072031233563043], 'sparsity': [0.955866462585034, 0.0003942105365294669]}, 'fivemodels/l1swap.pt': {'avg_logit_diff': [1.691388753671199, 0.38077573429620404], 'stop_time': [8.689433383941651, 0.032214451386828075], 'sparsity': [0.9584242517006804, 0.00031917964373040855]}, 'fivemodels/fully_dense.pt': {'avg_logit_diff': [7.121328021347523, 1.5863204516236806], 'stop_time': [8.652990436553955, 0.010286117643608305], 'sparsity': [0.8635901445578231, 1.7738419765758813e-05]}}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "def mean_confidence_interval(data):\n",
    "    n = len(data)\n",
    "    mean = np.mean(data)\n",
    "    std_err = stats.sem(data)\n",
    "    h = std_err * stats.t.ppf((1 + 0.95) / 2, n - 1)  # 95% CI\n",
    "\n",
    "    return mean, h # mean - h, mean + h\n",
    "\n",
    "metrics = [\"avg_logit_diff\", \"stop_time\", \"sparsity\"]\n",
    "\n",
    "avg_results = {}\n",
    "\n",
    "for i in range(5):\n",
    "    temp = {}\n",
    "    for met in metrics:\n",
    "        mean, h = mean_confidence_interval(model_result[i][met])\n",
    "        # print(f\"Model: {models[i]}, metric: {met}: Mean = {mean}, 95% CI = ({ci_lower}, {ci_upper})\")\n",
    "        temp[met] = [mean, h]\n",
    "        # print(model_result[i][\"avg_logit_diff\"])\n",
    "        # print(model_result[i][\"stop_time\"])\n",
    "        # print(model_result[i][\"sparsity\"])\n",
    "        # print(\"-\"*20\n",
    "    avg_results[models[i]] = temp\n",
    "\n",
    "print(avg_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg_logit_diff': [1.3281621509492398, 0.30065939075883985], 'stop_time': [8.453461146354675, 0.007918620268235272], 'sparsity': [0.9839527806122449, 0.0013898862397499897]}\n",
      "-------\n",
      "{'avg_logit_diff': [1.4663056277781723, 0.3158338925922389], 'stop_time': [8.647523629665375, 0.1009415653694821], 'sparsity': [0.98147425170068, 0.0008743501029641102]}\n",
      "-------\n",
      "{'avg_logit_diff': [1.382896779835224, 0.27016060535554876], 'stop_time': [8.607308506965637, 0.02072031233563043], 'sparsity': [0.955866462585034, 0.0003942105365294669]}\n",
      "-------\n",
      "{'avg_logit_diff': [1.691388753671199, 0.38077573429620404], 'stop_time': [8.689433383941651, 0.032214451386828075], 'sparsity': [0.9584242517006804, 0.00031917964373040855]}\n",
      "-------\n",
      "{'avg_logit_diff': [7.121328021347523, 1.5863204516236806], 'stop_time': [8.652990436553955, 0.010286117643608305], 'sparsity': [0.8635901445578231, 1.7738419765758813e-05]}\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "for k in avg_results.keys():\n",
    "    print(avg_results[k])\n",
    "    print(\"-------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bimt\n",
      "l1local\n",
      "l1only\n",
      "l1swap\n",
      "fully_dense\n"
     ]
    }
   ],
   "source": [
    "for i, txt in enumerate(models):\n",
    "    t = txt.split(\"/\")[-1].split('.')[0]\n",
    "    print(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bootstrap_st.json', 'w') as json_file:\n",
    "    json.dump(avg_results, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg_logit_diff': [1.2737224330881716, 0.18334597917278106], 'stop_time': [9.376142251491547, 0.021555709196431627, 9.376142251491547, 0.021555709196431627, 9.376142251491547, 0.021555709196431627, 9.376142251491547, 0.021555709196431627, 9.376142251491547, 0.021555709196431627, 9.376142251491547, 0.021555709196431627, 9.376142251491547, 0.021555709196431627, 9.376142251491547, 0.021555709196431627, 9.376142251491547, 0.021555709196431627, 9.376142251491547, 0.021555709196431627], 'sparsity': [0.9859922108843537, 0.0009761369140441251]}\n",
      "{'avg_logit_diff': [1.7953282489763893, 0.2892961738550312], 'stop_time': [9.431681668758392, 0.032933812391417676, 9.431681668758392, 0.032933812391417676, 9.431681668758392, 0.032933812391417676, 9.431681668758392, 0.032933812391417676, 9.431681668758392, 0.032933812391417676, 9.431681668758392, 0.032933812391417676, 9.431681668758392, 0.032933812391417676, 9.431681668758392, 0.032933812391417676, 9.431681668758392, 0.032933812391417676, 9.431681668758392, 0.032933812391417676], 'sparsity': [0.9824486819727891, 0.001331170306963688]}\n",
      "{'avg_logit_diff': [2.3412293231898333, 0.4927145977314583], 'stop_time': [9.433519232273103, 0.011173138722201803, 9.433519232273103, 0.011173138722201803, 9.433519232273103, 0.011173138722201803, 9.433519232273103, 0.011173138722201803, 9.433519232273103, 0.011173138722201803, 9.433519232273103, 0.011173138722201803, 9.433519232273103, 0.011173138722201803, 9.433519232273103, 0.011173138722201803, 9.433519232273103, 0.011173138722201803, 9.433519232273103, 0.011173138722201803], 'sparsity': [0.9551209268707481, 0.00036423432236495044]}\n",
      "{'avg_logit_diff': [1.9539728549098883, 0.2829784542176342], 'stop_time': [9.484722292423248, 0.011052775413489948, 9.484722292423248, 0.011052775413489948, 9.484722292423248, 0.011052775413489948, 9.484722292423248, 0.011052775413489948, 9.484722292423248, 0.011052775413489948, 9.484722292423248, 0.011052775413489948, 9.484722292423248, 0.011052775413489948, 9.484722292423248, 0.011052775413489948, 9.484722292423248, 0.011052775413489948, 9.484722292423248, 0.011052775413489948], 'sparsity': [0.9630037074829934, 0.0010498596172144941]}\n",
      "{'avg_logit_diff': [8.943790509925615, 1.9791072316707232], 'stop_time': [9.539580059051513, 0.014945613357212752, 9.539580059051513, 0.014945613357212752, 9.539580059051513, 0.014945613357212752, 9.539580059051513, 0.014945613357212752, 9.539580059051513, 0.014945613357212752, 9.539580059051513, 0.014945613357212752, 9.539580059051513, 0.014945613357212752, 9.539580059051513, 0.014945613357212752, 9.539580059051513, 0.014945613357212752, 9.539580059051513, 0.014945613357212752], 'sparsity': [0.8635494642857143, 1.9237710682374507e-05]}\n"
     ]
    }
   ],
   "source": [
    "for k,v in avg_results.items():\n",
    "    v[\"stop_time\"] = v[\"stop_time\"]*10\n",
    "\n",
    "for k,v in avg_results.items():\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "data = avg_results\n",
    "\n",
    "# Extracting the values for plotting\n",
    "models = list(data.keys())\n",
    "avg_logit_diff_values = [data[model]['avg_logit_diff'][0] for model in models]\n",
    "avg_logit_diff_errors = [data[model]['avg_logit_diff'][1] for model in models]\n",
    "\n",
    "time_values = [data[model]['stop_time'][0]*10 for model in models]\n",
    "time_errors = [data[model]['stop_time'][1]*10 for model in models]\n",
    "\n",
    "sparsity_values = [data[model]['sparsity'][0] for model in models]\n",
    "sparsity_errors = [data[model]['sparsity'][1] for model in models]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "# plt.errorbar(sparsity_values, avg_logit_diff_values, xerr=sparsity_errors, yerr=avg_logit_diff_errors, fmt='o', ecolor='gray', elinewidth=3, capsize=0)\n",
    "plt.errorbar(sparsity_values, time_values, yerr=time_errors, fmt='o', ecolor='gray', elinewidth=3, capsize=0)\n",
    "\n",
    "# Labeling\n",
    "plt.xlabel('Sparsity')\n",
    "plt.ylabel('Circuit Discovery Time')\n",
    "plt.title('Sparsity vs Circuit Discovery Time')\n",
    "plt.xticks(np.arange(min(sparsity_values), max(sparsity_values), 0.01))\n",
    "plt.grid(True)\n",
    "\n",
    "# Annotating the models\n",
    "for i, txt in enumerate(models):\n",
    "    t = txt.split(\"/\")[-1].split('.')[0]\n",
    "    plt.annotate(t, (sparsity_values[i]+0.0009, time_values[i]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fivemodels/bimt.pt': {'avg_logit_diff': [1.3281621509492398, 0.30065939075883985], 'stop_time': [8.453461146354675, 0.007918620268235272], 'sparsity': [0.9839527806122449, 0.0013898862397499897]}, 'fivemodels/l1local.pt': {'avg_logit_diff': [1.4663056277781723, 0.3158338925922389], 'stop_time': [8.647523629665375, 0.1009415653694821], 'sparsity': [0.98147425170068, 0.0008743501029641102]}, 'fivemodels/l1only.pt': {'avg_logit_diff': [1.382896779835224, 0.27016060535554876], 'stop_time': [8.607308506965637, 0.02072031233563043], 'sparsity': [0.955866462585034, 0.0003942105365294669]}, 'fivemodels/l1swap.pt': {'avg_logit_diff': [1.691388753671199, 0.38077573429620404], 'stop_time': [8.689433383941651, 0.032214451386828075], 'sparsity': [0.9584242517006804, 0.00031917964373040855]}, 'fivemodels/fully_dense.pt': {'avg_logit_diff': [7.121328021347523, 1.5863204516236806], 'stop_time': [8.652990436553955, 0.010286117643608305], 'sparsity': [0.8635901445578231, 1.7738419765758813e-05]}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Replace 'path_to_file.json' with the path to your JSON file\n",
    "file_path = 'bootstrap_st.json'\n",
    "\n",
    "# Open the JSON file and load its contents into a Python object\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Now 'data' is a Python object containing the data from the JSON file\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg_logit_diff': [1.3281621509492398, 0.30065939075883985], 'stop_time': [84.53461146354675, 0.07918620268235271], 'sparsity': [0.9839527806122449, 0.0013898862397499897]}\n",
      "{'avg_logit_diff': [1.4663056277781723, 0.3158338925922389], 'stop_time': [86.47523629665375, 1.009415653694821], 'sparsity': [0.98147425170068, 0.0008743501029641102]}\n",
      "{'avg_logit_diff': [1.382896779835224, 0.27016060535554876], 'stop_time': [86.07308506965637, 0.2072031233563043], 'sparsity': [0.955866462585034, 0.0003942105365294669]}\n",
      "{'avg_logit_diff': [1.691388753671199, 0.38077573429620404], 'stop_time': [86.8943338394165, 0.32214451386828075], 'sparsity': [0.9584242517006804, 0.00031917964373040855]}\n",
      "{'avg_logit_diff': [7.121328021347523, 1.5863204516236806], 'stop_time': [86.52990436553955, 0.10286117643608304], 'sparsity': [0.8635901445578231, 1.7738419765758813e-05]}\n"
     ]
    }
   ],
   "source": [
    "for k,v in data.items():\n",
    "    v[\"stop_time\"][0] = v[\"stop_time\"][0]*10\n",
    "    v[\"stop_time\"][1] = v[\"stop_time\"][1]*10\n",
    "\n",
    "\n",
    "for k,v in data.items():\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bootstrap_st.json', 'w') as json_file:\n",
    "        json.dump(data, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "Done with  fivemodels/bimt.pt\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "Done with  fivemodels/l1local.pt\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "Done with  fivemodels/l1only.pt\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "Done with  fivemodels/l1swap.pt\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "Done with  fivemodels/fully_dense.pt\n"
     ]
    }
   ],
   "source": [
    "models = [\"fivemodels/bimt.pt\", \"fivemodels/l1local.pt\", \"fivemodels/l1only.pt\", \"fivemodels/l1swap.pt\", \"fivemodels/fully_dense.pt\"]\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import random\n",
    "import gc\n",
    "\n",
    "# Assuming you have a function `circuit_discovery` that returns top_15_neurons, avg_logit_diff, stop_time, sparsity\n",
    "# def circuit_discovery(model, data_loader): ...\n",
    "\n",
    "# Your DataLoader and models setup remains the same\n",
    "final_loader = DataLoader(final_dataset, batch_size=1, shuffle=True)\n",
    "# models = [\"fivemodels/bimt.pt\", \"fivemodels/l1local.pt\", \"fivemodels/l1only.pt\", \"fivemodels/l1swap.pt\", \"fivemodels/fully_dense.pt\"]\n",
    "models = [\"fivemodels/bimt.pt\", \"fivemodels/l1local.pt\", \"fivemodels/l1only.pt\", \"fivemodels/l1swap.pt\", \"fivemodels/fully_dense.pt\"]\n",
    "\n",
    "# Number of bootstrap samples\n",
    "n_bootstrap_samples = 20  # or any other number you deem sufficient\n",
    "\n",
    "avg_inf_time = {0:[], 1:[], 2:[], 3:[], 4:[]}\n",
    "for val, model_path in enumerate(models):\n",
    "    mlp = BioMLP2D(shp=(784,100,100,10)).to(\"cpu\")\n",
    "    mlp.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    for _ in range(n_bootstrap_samples):\n",
    "        \n",
    "        subset_indices = random.sample(range(len(final_dataset)), 1000)\n",
    "        subset = Subset(final_dataset, subset_indices)\n",
    "        # Create a DataLoader for the subset\n",
    "        avg_inf = 0\n",
    "        subset_loader = DataLoader(subset, batch_size=1, shuffle=True)\n",
    "        for i, (image1, image2) in enumerate(subset_loader):\n",
    "            clean_tensor = image2\n",
    "            start = time.time()\n",
    "            mlp.eval()\n",
    "            with torch.no_grad():\n",
    "                og_op = mlp(clean_tensor)\n",
    "                avg_inf += time.time()-start\n",
    "        avg_inf_time[val].append(avg_inf)\n",
    "        # Store the results\n",
    "        gc.collect()\n",
    "        print(\"-\"*20)\n",
    "\n",
    "    # Store results for this model\n",
    "    print(\"Done with \", model_path)\n",
    "    # model_result[val] = bootstrap_results\n",
    "    with open('inf.json', 'w') as json_file:\n",
    "        json.dump(avg_inf_time, json_file)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [0.07564640045166016,\n",
       "  0.06342625617980957,\n",
       "  0.06416988372802734,\n",
       "  0.06525444984436035,\n",
       "  0.07244682312011719,\n",
       "  0.06749272346496582,\n",
       "  0.06493568420410156,\n",
       "  0.06429672241210938,\n",
       "  0.0651404857635498,\n",
       "  0.0650787353515625,\n",
       "  0.06552338600158691,\n",
       "  0.06455111503601074,\n",
       "  0.06476759910583496,\n",
       "  0.06479358673095703,\n",
       "  0.06464099884033203,\n",
       "  0.06485462188720703,\n",
       "  0.06475615501403809,\n",
       "  0.0646209716796875,\n",
       "  0.06462812423706055,\n",
       "  0.06441211700439453],\n",
       " 1: [0.06493806838989258,\n",
       "  0.06451249122619629,\n",
       "  0.06571793556213379,\n",
       "  0.06485414505004883,\n",
       "  0.06523489952087402,\n",
       "  0.06530356407165527,\n",
       "  0.06497740745544434,\n",
       "  0.06451201438903809,\n",
       "  0.06500577926635742,\n",
       "  0.06473088264465332,\n",
       "  0.06561613082885742,\n",
       "  0.06468605995178223,\n",
       "  0.06493687629699707,\n",
       "  0.06480216979980469,\n",
       "  0.06472921371459961,\n",
       "  0.06464505195617676,\n",
       "  0.06466484069824219,\n",
       "  0.06447505950927734,\n",
       "  0.06493473052978516,\n",
       "  0.06433558464050293],\n",
       " 2: [0.06441187858581543,\n",
       "  0.06444287300109863,\n",
       "  0.06495022773742676,\n",
       "  0.06510019302368164,\n",
       "  0.06455278396606445,\n",
       "  0.06437134742736816,\n",
       "  0.0641322135925293,\n",
       "  0.0650033950805664,\n",
       "  0.06430530548095703,\n",
       "  0.06518387794494629,\n",
       "  0.06503701210021973,\n",
       "  0.06455564498901367,\n",
       "  0.06448507308959961,\n",
       "  0.06508541107177734,\n",
       "  0.0649559497833252,\n",
       "  0.06435894966125488,\n",
       "  0.0652313232421875,\n",
       "  0.06418275833129883,\n",
       "  0.06427788734436035,\n",
       "  0.06449699401855469],\n",
       " 3: [0.0649561882019043,\n",
       "  0.06456732749938965,\n",
       "  0.06497645378112793,\n",
       "  0.06474590301513672,\n",
       "  0.06479358673095703,\n",
       "  0.06449174880981445,\n",
       "  0.06503772735595703,\n",
       "  0.06525301933288574,\n",
       "  0.06461668014526367,\n",
       "  0.06490492820739746,\n",
       "  0.06512856483459473,\n",
       "  0.06529569625854492,\n",
       "  0.06518912315368652,\n",
       "  0.06541919708251953,\n",
       "  0.06492090225219727,\n",
       "  0.06490826606750488,\n",
       "  0.06478190422058105,\n",
       "  0.06507253646850586,\n",
       "  0.0652914047241211,\n",
       "  0.06464862823486328],\n",
       " 4: [0.06503558158874512,\n",
       "  0.06421828269958496,\n",
       "  0.06555676460266113,\n",
       "  0.06561279296875,\n",
       "  0.06532144546508789,\n",
       "  0.0654754638671875,\n",
       "  0.06444883346557617,\n",
       "  0.07051992416381836,\n",
       "  0.06469249725341797,\n",
       "  0.06451654434204102,\n",
       "  0.06565546989440918,\n",
       "  0.06462550163269043,\n",
       "  0.06463074684143066,\n",
       "  0.06411147117614746,\n",
       "  0.064849853515625,\n",
       "  0.06510019302368164,\n",
       "  0.06362295150756836,\n",
       "  0.06567740440368652,\n",
       "  0.06555891036987305,\n",
       "  0.06489825248718262]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_inf_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.06577184200286865, 0.0013927661991169052)\n",
      "(0.06488064527511597, 0.0001699680190952522)\n",
      "(0.0646560549736023, 0.00017137254463719725)\n",
      "(0.06494998931884766, 0.00012326044860905294)\n",
      "(0.06520644426345826, 0.0006449584712101988)\n"
     ]
    }
   ],
   "source": [
    "def mean_confidence_interval(data):\n",
    "    n = len(data)\n",
    "    mean = np.mean(data)\n",
    "    std_err = stats.sem(data)\n",
    "    h = std_err * stats.t.ppf((1 + 0.95) / 2, n - 1)  # 95% CI\n",
    "\n",
    "    return mean, h # mean - h, mean + h\n",
    "\n",
    "for k, v in avg_inf_time.items():\n",
    "    print(mean_confidence_interval(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/zephyr/Documents/Learnings/Research Projects/ModularMechInt/ModuMechInt/bootstrapping.ipynb Cell 22\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zephyr/Documents/Learnings/Research%20Projects/ModularMechInt/ModuMechInt/bootstrapping.ipynb#X30sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m cis \u001b[39m=\u001b[39m [ci \u001b[39mfor\u001b[39;00m mean, ci \u001b[39min\u001b[39;00m inference_time_data]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zephyr/Documents/Learnings/Research%20Projects/ModularMechInt/ModuMechInt/bootstrapping.ipynb#X30sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# Plotting\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/zephyr/Documents/Learnings/Research%20Projects/ModularMechInt/ModuMechInt/bootstrapping.ipynb#X30sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m, \u001b[39m6\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zephyr/Documents/Learnings/Research%20Projects/ModularMechInt/ModuMechInt/bootstrapping.ipynb#X30sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# plt.errorbar(model_names, means, yerr=cis, fmt='o', ecolor='gray', elinewidth=3, capsize=5)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zephyr/Documents/Learnings/Research%20Projects/ModularMechInt/ModuMechInt/bootstrapping.ipynb#X30sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zephyr/Documents/Learnings/Research%20Projects/ModularMechInt/ModuMechInt/bootstrapping.ipynb#X30sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# Error bars for all points\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/zephyr/Documents/Learnings/Research%20Projects/ModularMechInt/ModuMechInt/bootstrapping.ipynb#X30sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m plt\u001b[39m.\u001b[39merrorbar(model_names, means, yerr\u001b[39m=\u001b[39mcis, fmt\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mo\u001b[39m\u001b[39m'\u001b[39m, ecolor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgray\u001b[39m\u001b[39m'\u001b[39m, elinewidth\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, capsize\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "inference_time_data = [\n",
    "    (0.06577184200286865, 0.0013927661991169052),\n",
    "    (0.06488064527511597, 0.0001699680190952522),\n",
    "    (0.0646560549736023, 0.00017137254463719725),\n",
    "    (0.06494998931884766, 0.00012326044860905294),\n",
    "    (0.06520644426345826, 0.0006449584712101988)\n",
    "]\n",
    "\n",
    "model_names = [\"BIMT\", \"L1+Local\", \"L1Only\", \"L1+Swap\", \"FullyDense\"]\n",
    "\n",
    "# Extracting mean values and confidence intervals\n",
    "means = [mean for mean, ci in inference_time_data]\n",
    "cis = [ci for mean, ci in inference_time_data]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.errorbar(model_names, means, yerr=cis, fmt='o', ecolor='gray', elinewidth=3, capsize=5)\n",
    "\n",
    "# Labeling\n",
    "plt.xlabel('Model Name')\n",
    "plt.ylabel('Inference Time (mean ± 95% CI)')\n",
    "plt.title('Inference Time for Different Models')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = [\"fivemodels/bimt.pt\", \"fivemodels/l1local.pt\", \"fivemodels/l1only.pt\", \"fivemodels/l1swap.pt\", \"fivemodels/fully_dense.pt\"]\n",
    "\n",
    "# model_result = {}\n",
    "# for val, model in enumerate(models):\n",
    "#     mlp = BioMLP2D(shp=(784,100,100,10)).to(\"cpu\")\n",
    "#     mlp.load_state_dict(torch.load(model))\n",
    "\n",
    "#     value_dict = defaultdict(lambda: {'sum': 0, 'count': 0})\n",
    "#     start = time.time()\n",
    "#     for i, (image1, image2) in enumerate(final_loader):\n",
    "#         sorted_neurons =  circuit_discovery(mlp, image2, image1)\n",
    "#         for layer, neuron, value in sorted_neurons:\n",
    "#             value_dict[(layer, neuron)]['sum'] += value\n",
    "#             value_dict[(layer, neuron)]['count'] += 1\n",
    "#         if i % 100 == 0:\n",
    "#             print(\"iter: \", i)\n",
    "\n",
    "#     average_values = {}\n",
    "#     for key, data in value_dict.items():\n",
    "#         average = data['sum'] / data['count']\n",
    "#         average_values[key] = average\n",
    "\n",
    "#     # print(average_values.items())\n",
    "\n",
    "#     data = average_values\n",
    "#     # Separate the dictionary for each layer and sort according to the logit value\n",
    "#     layer_dict = {}\n",
    "#     for (layer, neuron), logit in data.items():\n",
    "#         if layer not in layer_dict:\n",
    "#             layer_dict[layer] = []\n",
    "#         layer_dict[layer].append(((layer, neuron), logit))\n",
    "\n",
    "#     # Sort each layer's list by logit value in descending order\n",
    "#     for layer in layer_dict:\n",
    "#         layer_dict[layer].sort(key=lambda x: x[1], reverse=False)\n",
    "\n",
    "#     # stop = \n",
    "#     top_15 = get_top_n_from_each_layer(layer_dict, 25)\n",
    "#     # model_result[val] = top_15\n",
    "#     stop_time = time.time()-start\n",
    "#     print(\"Model: \", model)\n",
    "#     print(\"Time to discover circuit: \", time.time()-start)\n",
    "\n",
    "#     avg_logit_diff = 0\n",
    "#     for i, (image1, image2) in enumerate(final_loader):\n",
    "#         clean_tensor = image2\n",
    "#         mlp.eval()\n",
    "#         with torch.no_grad():\n",
    "#             og_op = mlp(clean_tensor)\n",
    "#             clean_activations = activations.copy()\n",
    "\n",
    "#         sub_graph_act = [a.clone() for a in clean_activations]\n",
    "\n",
    "#         for inn_idx, sub_layer in enumerate(mlp.get_linear_layers()[1:]):\n",
    "#             # print(inn_idx+layer_idx)\n",
    "#             zero_tensor = torch.zeros_like(sub_graph_act[inn_idx])\n",
    "#             zero_tensor[0, torch.tensor(top_15[inn_idx])] = sub_graph_act[inn_idx][0, torch.tensor(top_15[inn_idx])]\n",
    "#             sub_graph_act[inn_idx] = zero_tensor\n",
    "#             # print(sub_graph_act[inn_idx].shape)\n",
    "#             sub_graph_act[inn_idx+1] = sub_layer(sub_graph_act[inn_idx])\n",
    "\n",
    "#         avg_logit_diff += measure_improvement(sub_graph_act[-1], og_op)\n",
    "#         # break\n",
    "#     avg_logit_diff = avg_logit_diff/len(final_loader)\n",
    "#     print(\"Average Logit Diff: \", avg_logit_diff)\n",
    "\n",
    "#     for ii in range(3):\n",
    "#         biolinear = mlp.linears[ii]\n",
    "#         p = biolinear.linear.weight.clone()\n",
    "#         if ii == 0:\n",
    "#             p = sparsify2circuit_left(p, torch.tensor(model_result[val][0][ii]))\n",
    "#         else:\n",
    "#             p = sparsify2circuit_right(p, torch.tensor(model_result[val][0][ii]))\n",
    "#             p = sparsify2circuit_left(p, torch.tensor(model_result[val][0][ii]))\n",
    "\n",
    "#         W = p.T.detach().numpy()\n",
    "#         n_sparsity = (np.abs(W)<0.0009).sum()\n",
    "#         avg_spar+=n_sparsity/(W.shape[0]*W.shape[1])\n",
    "#         # print(\"Percentage Sparsity:\", n_sparsity/(W.shape[0]*W.shape[1]))\n",
    "#     avg_spar = avg_spar/3\n",
    "#     model_result[val] = [top_15, avg_logit_diff, stop_time, avg_spar]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modmi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
